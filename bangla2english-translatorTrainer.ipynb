{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:26:42.023628Z","iopub.status.busy":"2024-03-09T14:26:42.022924Z","iopub.status.idle":"2024-03-09T14:26:48.536760Z","shell.execute_reply":"2024-03-09T14:26:48.535720Z","shell.execute_reply.started":"2024-03-09T14:26:42.023572Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tesla P100-PCIE-16GB\n"]}],"source":["import math\n","import torchtext\n","import torch\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","from collections import Counter\n","from torchtext.vocab import Vocab\n","import io\n","import time\n","import pandas as pd\n","import numpy as np\n","import pickle\n","import sentencepiece as spm\n","from torch.nn import TransformerEncoder, TransformerDecoder, TransformerEncoderLayer, TransformerDecoderLayer\n","torch.manual_seed(0)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(torch.cuda.get_device_name(0))"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-09T14:26:50.965456Z","iopub.status.busy":"2024-03-09T14:26:50.964358Z","iopub.status.idle":"2024-03-09T14:26:50.969731Z","shell.execute_reply":"2024-03-09T14:26:50.968814Z","shell.execute_reply.started":"2024-03-09T14:26:50.965422Z"},"trusted":true},"outputs":[],"source":["be_path = \"/kaggle/input/bengali-to-english-datasets/Bangla_text.txt\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:26:53.664278Z","iopub.status.busy":"2024-03-09T14:26:53.663389Z","iopub.status.idle":"2024-03-09T14:26:53.668819Z","shell.execute_reply":"2024-03-09T14:26:53.667870Z","shell.execute_reply.started":"2024-03-09T14:26:53.664246Z"},"trusted":true},"outputs":[],"source":["def read_bdata(be_path):\n","    with open(be_path, \"r\") as b_file:\n","        data = b_file.readlines()\n","    return data"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:26:55.415538Z","iopub.status.busy":"2024-03-09T14:26:55.414604Z","iopub.status.idle":"2024-03-09T14:27:02.589864Z","shell.execute_reply":"2024-03-09T14:27:02.588972Z","shell.execute_reply.started":"2024-03-09T14:26:55.415506Z"},"trusted":true},"outputs":[],"source":["be_data = read_bdata(be_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:02.591862Z","iopub.status.busy":"2024-03-09T14:27:02.591513Z","iopub.status.idle":"2024-03-09T14:27:02.663900Z","shell.execute_reply":"2024-03-09T14:27:02.662643Z","shell.execute_reply.started":"2024-03-09T14:27:02.591835Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['আবার সবাইকে যার যার ইচ্ছামতো চলতে দিলে সমতা রক্ষা করা অসম্ভব হয়ে যায়।\\n',\n"," 'তুরুপ\\n',\n"," 'পদদলিত করা\\n',\n"," '\"সেগুলো হৃদয়কে উষ্ণ করে এবং রোজকার বোঝাগুলোকে হালকা করে।\\n',\n"," 'আমি ভালোবাসি তোমাকে ।\\n',\n"," 'পোর্ট কোম্পানি লিমিটেড - কেপিসিএল\\n',\n"," 'তোলপাড়\\n',\n"," 'এছাড়াও ক্লেমঁসো উইলসনের ১৪ দফার ব্যাপারে সংশয়ী এবং হতাশ ছিলেন। তিনি অভিযোগ করে বলেন, \"মিস্টার উইলসনের ১৪ দফা বিরক্তিকর।\\n',\n"," 'আল-জাজিরার সঙ্গে জালুদের সাক্ষাতকার এবং তার দৃষ্টিভঙ্গীর বিষয়ে অন্যান্য টুইটার ব্যবহারকারীরা মন্তব্য করেন:\\n',\n"," 'ক্লাব.\\n']"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["be_data[:10]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:05.730299Z","iopub.status.busy":"2024-03-09T14:27:05.729906Z","iopub.status.idle":"2024-03-09T14:27:07.058243Z","shell.execute_reply":"2024-03-09T14:27:07.057316Z","shell.execute_reply.started":"2024-03-09T14:27:05.730272Z"},"trusted":true},"outputs":[],"source":["bdata=[string.replace('\\n', '') for string in be_data]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:08.277300Z","iopub.status.busy":"2024-03-09T14:27:08.276901Z","iopub.status.idle":"2024-03-09T14:27:08.283705Z","shell.execute_reply":"2024-03-09T14:27:08.282748Z","shell.execute_reply.started":"2024-03-09T14:27:08.277271Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['আবার সবাইকে যার যার ইচ্ছামতো চলতে দিলে সমতা রক্ষা করা অসম্ভব হয়ে যায়।',\n"," 'তুরুপ',\n"," 'পদদলিত করা',\n"," '\"সেগুলো হৃদয়কে উষ্ণ করে এবং রোজকার বোঝাগুলোকে হালকা করে।',\n"," 'আমি ভালোবাসি তোমাকে ।',\n"," 'পোর্ট কোম্পানি লিমিটেড - কেপিসিএল',\n"," 'তোলপাড়',\n"," 'এছাড়াও ক্লেমঁসো উইলসনের ১৪ দফার ব্যাপারে সংশয়ী এবং হতাশ ছিলেন। তিনি অভিযোগ করে বলেন, \"মিস্টার উইলসনের ১৪ দফা বিরক্তিকর।',\n"," 'আল-জাজিরার সঙ্গে জালুদের সাক্ষাতকার এবং তার দৃষ্টিভঙ্গীর বিষয়ে অন্যান্য টুইটার ব্যবহারকারীরা মন্তব্য করেন:',\n"," 'ক্লাব.']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["bdata[:10]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:10.621384Z","iopub.status.busy":"2024-03-09T14:27:10.620967Z","iopub.status.idle":"2024-03-09T14:27:14.041145Z","shell.execute_reply":"2024-03-09T14:27:14.040159Z","shell.execute_reply.started":"2024-03-09T14:27:10.621350Z"},"trusted":true},"outputs":[],"source":["en_path = \"/kaggle/input/bengali-to-english-datasets/English_text.txt\"\n","\n","def read_edata(en_path):\n","    with open(en_path, \"r\") as e_file:\n","        data = e_file.readlines()\n","    return data\n","\n","en_data = read_edata(en_path)\n","edata=[string.replace('\\n', '') for string in en_data]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T13:49:01.790318Z","iopub.status.busy":"2024-03-09T13:49:01.789635Z","iopub.status.idle":"2024-03-09T13:49:01.796138Z","shell.execute_reply":"2024-03-09T13:49:01.795198Z","shell.execute_reply.started":"2024-03-09T13:49:01.790283Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Guaranteeing that every individual will be free to do as he wishes inevitably short-changes equality.',\n"," 'trump',\n"," 'overrides',\n"," '\"They warm the heart and ease the daily load.',\n"," 'I love you.',\n"," 'Port Company Limited - KPCL',\n"," 'commotions',\n"," 'Clemenceau also expressed skepticism and frustration with Wilson\\'s Fourteen Points: \"Mr. Wilson bores me with his fourteen points\", complained Clemenceau.',\n"," \"Other Twitter users went on commenting on Jalloud's interview for Al-Jazeera and his attitude:\",\n"," 'Club.']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["edata[:10]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T13:49:01.799903Z","iopub.status.busy":"2024-03-09T13:49:01.799612Z","iopub.status.idle":"2024-03-09T13:49:02.038502Z","shell.execute_reply":"2024-03-09T13:49:02.037525Z","shell.execute_reply.started":"2024-03-09T13:49:01.799879Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2659723"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["len(bdata)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T13:49:02.040035Z","iopub.status.busy":"2024-03-09T13:49:02.039733Z","iopub.status.idle":"2024-03-09T13:49:02.050308Z","shell.execute_reply":"2024-03-09T13:49:02.049427Z","shell.execute_reply.started":"2024-03-09T13:49:02.040010Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2659723"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(edata)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:18.463590Z","iopub.status.busy":"2024-03-09T14:27:18.462857Z","iopub.status.idle":"2024-03-09T14:27:18.698437Z","shell.execute_reply":"2024-03-09T14:27:18.697319Z","shell.execute_reply.started":"2024-03-09T14:27:18.463553Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2127000"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["trainbn = [i for i in bdata[:-532723]]\n","val_bn = [i for i in bdata[-532723:]]\n","len(trainbn)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:22.803065Z","iopub.status.busy":"2024-03-09T14:27:22.802666Z","iopub.status.idle":"2024-03-09T14:27:22.809642Z","shell.execute_reply":"2024-03-09T14:27:22.808509Z","shell.execute_reply.started":"2024-03-09T14:27:22.803036Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['নেলী লুথছার',\n"," 'অপরদিকে বৃহদাকার গভীর উপত্যকা',\n"," 'তার বলীখেলার জনপ্রিয়তা এখনও অক্ষুণ্ণ রয়েছে। খেলার আগে ঢোল বাজিয়ে প্রচারকার্য চালানো হয়।',\n"," 'তুমি গিয়ে পো কে সর্তক কর।',\n"," '৪ হাত = ১ ধনু (৬ ফুট)',\n"," 'ইতিহাস.',\n"," 'অনেকেই হয়তো তাকে চিনে না, তাকে গ্রাহ্য করে না, বা এমনকি তার কথা মনেও করে না, যদিও তিনিই সম্প্রদায়টিকে সরাসরি সাহায্য এবং উন্নতিতে সহায়তা করছেন।',\n"," 'বৈশিষ্ট্য যোগ করা সম্ভব হয়নি',\n"," 'এগারো শতকের ভাস্কর্যসমূহের পশ্চাৎপটের পাথরে লতাপাতা ও নানা উদ্ভিদ বিষয়ক অলঙ্করণ শোভা পায়। মূল মূর্তির গায়ে দেখা যায় অলঙ্কারের বাহুল্য এবং পাথর খোদাই করে সূক্ষ্ম কারুকাজ ফুটিয়ে তোলা হতো।',\n"," 'নির্বোধ']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["val_bn[:10]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:26.185895Z","iopub.status.busy":"2024-03-09T14:27:26.185004Z","iopub.status.idle":"2024-03-09T14:27:26.355652Z","shell.execute_reply":"2024-03-09T14:27:26.354662Z","shell.execute_reply.started":"2024-03-09T14:27:26.185863Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2127000"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["trainen = [i for i in edata[:-532723]]\n","val_en = [i for i in edata[-532723:]]\n","len(trainen)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T13:49:02.470415Z","iopub.status.busy":"2024-03-09T13:49:02.469952Z","iopub.status.idle":"2024-03-09T13:49:02.477109Z","shell.execute_reply":"2024-03-09T13:49:02.476235Z","shell.execute_reply.started":"2024-03-09T13:49:02.470380Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Nellie Lutcher as Herself',\n"," 'On the other side of an enormous deep valley',\n"," 'Bali khela is given advance publicity by beating drums.',\n"," '- You must warn Po.',\n"," '4 hath = 1 dhanu (6 feet)',\n"," 'History.',\n"," 'Many might not know him, care about him, or even remember him, though he is the one who directly helped and advanced the community.',\n"," 'Cannot add attribute',\n"," 'In the 11th century, however, increasing importance was given to vegetal decoration of the back slab, profuse ornamentation of the main figure, and minute execution of details.',\n"," 'ignorant.']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["val_en[:10]"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T13:49:02.478570Z","iopub.status.busy":"2024-03-09T13:49:02.478274Z","iopub.status.idle":"2024-03-09T13:49:02.486915Z","shell.execute_reply":"2024-03-09T13:49:02.486116Z","shell.execute_reply.started":"2024-03-09T13:49:02.478547Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['নেপালে নবায়নযোগ্য শক্তি হচ্ছে এমন একটা সেক্টর যা নেপালে ছড়িয়ে পড়ছে।',\n"," 'এটা আমাদের বর্তমান দিনের সমতুল্য পরিপূর্ণতাটিকে আরও ভালভাবে বুঝতে সাহায্য করবে।',\n"," 'ভুলত্রুটি সত্ত্বেও প্রার্থনায় নিবিষ্ট থাকুন',\n"," 'ভালোবাসা ছাড়া, রাগ ছাড়া, দুঃখ ছাড়া... নিশ্বাস নেয়া মাত্র ঘড়ির কাটার শব্দ ।',\n"," 'সংবেদনশীল করা',\n"," 'দেখতে চমৎকার, সার্জেন্ট।',\n"," '১৬০৫ খ্রিস্টাব্দে প্যারিসে জন্মগ্রহণকারী জে.বি টেভার্নিয়ার তাঁর বাবা গ্যাব্রিয়েলের কাছ থেকে ভূগোলচর্চা ও বিদেশ ভ্রমণের অনুপ্রেরণা লাভ করেন। তাঁর বাবা ছিলেন একজন বণিক ও ভূগোলবিদ।',\n"," 'এন্ডিমো স্টুডিওর কার্টুন, অনুমতিক্রমে প্রকাশিত।',\n"," '১৬৬০ সালে মুজ্জাম খান (মীর জুমলা) আবার রাজধানী ঢাকায় নিয়ে আসেন।',\n"," 'জাহানারা একদিনের আন্তর্জাতিকে অভিষেক ঘটে ২০১১ সালের ২৬ নভেম্বর আয়ারল্যান্ড মহিলা ক্রিকেট দলের বিরুদ্ধে।']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["trainbn[-10:]"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T13:49:02.488228Z","iopub.status.busy":"2024-03-09T13:49:02.487921Z","iopub.status.idle":"2024-03-09T13:49:02.496472Z","shell.execute_reply":"2024-03-09T13:49:02.495603Z","shell.execute_reply.started":"2024-03-09T13:49:02.488200Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Renewable energy in Nepal is a sector that is rapidly developing in Nepal.',\n"," 'This will help us better to understand the parallel fulfillment today.',\n"," 'Persevere in Prayer Despite Shortcomings',\n"," 'without love, without anger, without sorrow... breath is just a clock ticking.',\n"," 'sensitise',\n"," 'Look lively, Sergeant.',\n"," 'Born in Paris in 1605, Tavernier got the inspiration for acquiring knowledge in geography and traveling abroad from his father Gabriel, a merchant and a geographer.',\n"," 'Cartoon by Andimoo Studios, used with permission',\n"," 'In 1660, Muazzam Khan (Mir Jumla) again shifted the capital to Dhaka.',\n"," \"Alam made her ODI career against Ireland women's cricket team on November 26, 2011.\"]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["trainen[-10:]"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:31.326695Z","iopub.status.busy":"2024-03-09T14:27:31.326052Z","iopub.status.idle":"2024-03-09T14:27:31.331446Z","shell.execute_reply":"2024-03-09T14:27:31.330374Z","shell.execute_reply.started":"2024-03-09T14:27:31.326651Z"},"trusted":true},"outputs":[],"source":["import os\n","process_data_path = \"/kaggle/working/process_data\"\n","os.makedirs(process_data_path, exist_ok=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:33.818013Z","iopub.status.busy":"2024-03-09T14:27:33.817175Z","iopub.status.idle":"2024-03-09T14:27:33.823084Z","shell.execute_reply":"2024-03-09T14:27:33.822137Z","shell.execute_reply.started":"2024-03-09T14:27:33.817980Z"},"trusted":true},"outputs":[],"source":["def write_txt_file(file_path, data, encoding=\"utf-8\"):\n","    with open(file_path, 'w') as file:\n","        for key in data:\n","            if isinstance(key, list):\n","                key = key[0]\n","            file.write(key+\"\\n\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:36.511374Z","iopub.status.busy":"2024-03-09T14:27:36.510988Z","iopub.status.idle":"2024-03-09T14:27:38.727853Z","shell.execute_reply":"2024-03-09T14:27:38.726887Z","shell.execute_reply.started":"2024-03-09T14:27:36.511342Z"},"trusted":true},"outputs":[],"source":["write_txt_file(os.path.join(process_data_path, \"bn_data.txt\"), trainbn)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:38.955523Z","iopub.status.busy":"2024-03-09T14:27:38.954790Z","iopub.status.idle":"2024-03-09T14:27:40.046146Z","shell.execute_reply":"2024-03-09T14:27:40.045063Z","shell.execute_reply.started":"2024-03-09T14:27:38.955487Z"},"trusted":true},"outputs":[],"source":["write_txt_file(os.path.join(process_data_path,\"en_data.txt\"), trainen)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:41.615304Z","iopub.status.busy":"2024-03-09T14:27:41.614622Z","iopub.status.idle":"2024-03-09T14:27:41.620488Z","shell.execute_reply":"2024-03-09T14:27:41.619432Z","shell.execute_reply.started":"2024-03-09T14:27:41.615271Z"},"trusted":true},"outputs":[],"source":["def merge_data_write_txt_file(file_path, bn_data, en_data, encoding=\"utf-8\"):\n","    with open(file_path, 'w') as file:\n","        for be, en in zip(bn_data, en_data):\n","            file.write(be+\"\\t\"+en+\"\\n\")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:44.371527Z","iopub.status.busy":"2024-03-09T14:27:44.371139Z","iopub.status.idle":"2024-03-09T14:27:47.661434Z","shell.execute_reply":"2024-03-09T14:27:47.660505Z","shell.execute_reply.started":"2024-03-09T14:27:44.371496Z"},"trusted":true},"outputs":[],"source":["merge_data_write_txt_file(os.path.join(process_data_path, \"merge_data.txt\"), trainbn, trainen)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:47.663339Z","iopub.status.busy":"2024-03-09T14:27:47.663011Z","iopub.status.idle":"2024-03-09T14:27:47.668277Z","shell.execute_reply":"2024-03-09T14:27:47.667160Z","shell.execute_reply.started":"2024-03-09T14:27:47.663311Z"},"trusted":true},"outputs":[],"source":["model_path = \"model\"\n","os.makedirs(model_path, exist_ok = True)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:50.741793Z","iopub.status.busy":"2024-03-09T14:27:50.741369Z","iopub.status.idle":"2024-03-09T14:27:50.747614Z","shell.execute_reply":"2024-03-09T14:27:50.746655Z","shell.execute_reply.started":"2024-03-09T14:27:50.741762Z"},"trusted":true},"outputs":[],"source":["import sentencepiece as spm\n","\n","def train_tokenizer(text_path=\"text.txt\", model_prefix=\"model/bn_model\"):\n","    spm.SentencePieceTrainer.train(f'--input={text_path} --model_prefix={model_prefix} --user_defined_symbols=<sep>',min_frequency=2)\n","    bn_sp = spm.SentencePieceProcessor()\n","    bn_sp.load(os.path.join(model_path, 'bn_model.model'))"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:53.720127Z","iopub.status.busy":"2024-03-09T14:27:53.719733Z","iopub.status.idle":"2024-03-09T14:27:53.725284Z","shell.execute_reply":"2024-03-09T14:27:53.723945Z","shell.execute_reply.started":"2024-03-09T14:27:53.720097Z"},"trusted":true},"outputs":[],"source":["bn_data_path = \"/kaggle/working/process_data/bn_data.txt\"\n","en_data_path = \"/kaggle/working/process_data/en_data.txt\""]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:27:56.287642Z","iopub.status.busy":"2024-03-09T14:27:56.286891Z","iopub.status.idle":"2024-03-09T14:33:31.877488Z","shell.execute_reply":"2024-03-09T14:33:31.875933Z","shell.execute_reply.started":"2024-03-09T14:27:56.287609Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=/kaggle/working/process_data/bn_data.txt --model_prefix=model/bn_model --user_defined_symbols=<sep>\n","sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n","trainer_spec {\n","  input: /kaggle/working/process_data/bn_data.txt\n","  input_format: \n","  model_prefix: model/bn_model\n","  model_type: UNIGRAM\n","  vocab_size: 8000\n","  self_test_sample_size: 0\n","  character_coverage: 0.9995\n","  input_sentence_size: 0\n","  shuffle_input_sentence: 1\n","  seed_sentencepiece_size: 1000000\n","  shrinking_factor: 0.75\n","  max_sentence_length: 4192\n","  num_threads: 16\n","  num_sub_iterations: 2\n","  max_sentencepiece_length: 16\n","  split_by_unicode_script: 1\n","  split_by_number: 1\n","  split_by_whitespace: 1\n","  split_digits: 0\n","  pretokenization_delimiter: \n","  treat_whitespace_as_suffix: 0\n","  allow_whitespace_only_pieces: 0\n","  user_defined_symbols: <sep>\n","  required_chars: \n","  byte_fallback: 0\n","  vocabulary_output_piece_score: 1\n","  train_extremely_large_corpus: 0\n","  seed_sentencepieces_file: \n","  hard_vocab_limit: 1\n","  use_all_vocab: 0\n","  unk_id: 0\n","  bos_id: 1\n","  eos_id: 2\n","  pad_id: -1\n","  unk_piece: <unk>\n","  bos_piece: <s>\n","  eos_piece: </s>\n","  pad_piece: <pad>\n","  unk_surface:  ⁇ \n","  enable_differential_privacy: 0\n","  differential_privacy_noise_level: 0\n","  differential_privacy_clipping_threshold: 0\n","}\n","normalizer_spec {\n","  name: nmt_nfkc\n","  add_dummy_prefix: 1\n","  remove_extra_whitespaces: 1\n","  escape_whitespaces: 1\n","  normalization_rule_tsv: \n","}\n","denormalizer_spec {}\n","trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n","trainer_interface.cc(185) LOG(INFO) Loading corpus: /kaggle/working/process_data/bn_data.txt\n","trainer_interface.cc(380) LOG(WARNING) Found too long line (4598 > 4192).\n","trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n","trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n","trainer_interface.cc(147) LOG(INFO) Loaded 1000000 lines\n","trainer_interface.cc(147) LOG(INFO) Loaded 2000000 lines\n","trainer_interface.cc(124) LOG(WARNING) Too many sentences are loaded! (2126864), which may slow down training.\n","trainer_interface.cc(126) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n","trainer_interface.cc(129) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n","trainer_interface.cc(409) LOG(INFO) Loaded all 2126864 sentences\n","trainer_interface.cc(416) LOG(INFO) Skipped 136 too long sentences.\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <sep>\n","trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n","trainer_interface.cc(539) LOG(INFO) all chars count=146742784\n","trainer_interface.cc(550) LOG(INFO) Done: 99.9566% characters are covered.\n","trainer_interface.cc(560) LOG(INFO) Alphabet size=83\n","trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999566\n","trainer_interface.cc(592) LOG(INFO) Done! preprocessed 2126864 sentences.\n","unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n","unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=76675774\n","unigram_model_trainer.cc(312) LOG(INFO) Initialized 1000083 seed sentencepieces\n","trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 2126864\n","trainer_interface.cc(609) LOG(INFO) Done! 996156\n","unigram_model_trainer.cc(602) LOG(INFO) Using 996156 sentences for EM training\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=340259 obj=12.9969 num_tokens=2302037 num_tokens/piece=6.76554\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=291598 obj=10.5041 num_tokens=2304177 num_tokens/piece=7.9019\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=218661 obj=10.4767 num_tokens=2379606 num_tokens/piece=10.8826\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=218455 obj=10.4669 num_tokens=2382288 num_tokens/piece=10.9052\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=163836 obj=10.5016 num_tokens=2473475 num_tokens/piece=15.0973\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=163828 obj=10.4934 num_tokens=2474439 num_tokens/piece=15.1039\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=122871 obj=10.545 num_tokens=2571139 num_tokens/piece=20.9255\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=122871 obj=10.5336 num_tokens=2571107 num_tokens/piece=20.9253\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=92153 obj=10.6038 num_tokens=2671281 num_tokens/piece=28.9875\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=92153 obj=10.5901 num_tokens=2671278 num_tokens/piece=28.9874\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=69114 obj=10.675 num_tokens=2775753 num_tokens/piece=40.1619\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=69114 obj=10.6582 num_tokens=2775788 num_tokens/piece=40.1625\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=51835 obj=10.7642 num_tokens=2882347 num_tokens/piece=55.6062\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=51835 obj=10.7433 num_tokens=2882415 num_tokens/piece=55.6075\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=38876 obj=10.8744 num_tokens=2992396 num_tokens/piece=76.9728\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=38876 obj=10.8482 num_tokens=2992752 num_tokens/piece=76.982\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=29157 obj=11.0095 num_tokens=3115381 num_tokens/piece=106.848\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=29157 obj=10.9763 num_tokens=3115596 num_tokens/piece=106.856\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=21867 obj=11.17 num_tokens=3243760 num_tokens/piece=148.34\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=21867 obj=11.1288 num_tokens=3244016 num_tokens/piece=148.352\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=16400 obj=11.3607 num_tokens=3384211 num_tokens/piece=206.354\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=16400 obj=11.3113 num_tokens=3384524 num_tokens/piece=206.373\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12300 obj=11.589 num_tokens=3539866 num_tokens/piece=287.794\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12300 obj=11.5295 num_tokens=3540324 num_tokens/piece=287.831\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9225 obj=11.8489 num_tokens=3709891 num_tokens/piece=402.156\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9225 obj=11.7787 num_tokens=3710329 num_tokens/piece=402.204\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8800 obj=11.8311 num_tokens=3739930 num_tokens/piece=424.992\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8800 obj=11.8193 num_tokens=3740083 num_tokens/piece=425.009\n","trainer_interface.cc(687) LOG(INFO) Saving model: model/bn_model.model\n","trainer_interface.cc(699) LOG(INFO) Saving vocabs: model/bn_model.vocab\n"]}],"source":["train_tokenizer(\n","    text_path = bn_data_path,\n","    model_prefix = \"model/bn_model\"\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:35:35.278540Z","iopub.status.busy":"2024-03-09T14:35:35.277786Z","iopub.status.idle":"2024-03-09T14:40:32.491988Z","shell.execute_reply":"2024-03-09T14:40:32.490805Z","shell.execute_reply.started":"2024-03-09T14:35:35.278504Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=/kaggle/working/process_data/en_data.txt --model_prefix=model/en_model --user_defined_symbols=<sep>\n","sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n","trainer_spec {\n","  input: /kaggle/working/process_data/en_data.txt\n","  input_format: \n","  model_prefix: model/en_model\n","  model_type: UNIGRAM\n","  vocab_size: 8000\n","  self_test_sample_size: 0\n","  character_coverage: 0.9995\n","  input_sentence_size: 0\n","  shuffle_input_sentence: 1\n","  seed_sentencepiece_size: 1000000\n","  shrinking_factor: 0.75\n","  max_sentence_length: 4192\n","  num_threads: 16\n","  num_sub_iterations: 2\n","  max_sentencepiece_length: 16\n","  split_by_unicode_script: 1\n","  split_by_number: 1\n","  split_by_whitespace: 1\n","  split_digits: 0\n","  pretokenization_delimiter: \n","  treat_whitespace_as_suffix: 0\n","  allow_whitespace_only_pieces: 0\n","  user_defined_symbols: <sep>\n","  required_chars: \n","  byte_fallback: 0\n","  vocabulary_output_piece_score: 1\n","  train_extremely_large_corpus: 0\n","  seed_sentencepieces_file: \n","  hard_vocab_limit: 1\n","  use_all_vocab: 0\n","  unk_id: 0\n","  bos_id: 1\n","  eos_id: 2\n","  pad_id: -1\n","  unk_piece: <unk>\n","  bos_piece: <s>\n","  eos_piece: </s>\n","  pad_piece: <pad>\n","  unk_surface:  ⁇ \n","  enable_differential_privacy: 0\n","  differential_privacy_noise_level: 0\n","  differential_privacy_clipping_threshold: 0\n","}\n","normalizer_spec {\n","  name: nmt_nfkc\n","  add_dummy_prefix: 1\n","  remove_extra_whitespaces: 1\n","  escape_whitespaces: 1\n","  normalization_rule_tsv: \n","}\n","denormalizer_spec {}\n","trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n","trainer_interface.cc(185) LOG(INFO) Loading corpus: /kaggle/working/process_data/en_data.txt\n","trainer_interface.cc(380) LOG(WARNING) Found too long line (5232 > 4192).\n","trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n","trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n","trainer_interface.cc(147) LOG(INFO) Loaded 1000000 lines\n","trainer_interface.cc(147) LOG(INFO) Loaded 2000000 lines\n","trainer_interface.cc(124) LOG(WARNING) Too many sentences are loaded! (2126996), which may slow down training.\n","trainer_interface.cc(126) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n","trainer_interface.cc(129) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n","trainer_interface.cc(409) LOG(INFO) Loaded all 2126996 sentences\n","trainer_interface.cc(416) LOG(INFO) Skipped 4 too long sentences.\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <sep>\n","trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n","trainer_interface.cc(539) LOG(INFO) all chars count=149557323\n","trainer_interface.cc(550) LOG(INFO) Done: 99.9551% characters are covered.\n","trainer_interface.cc(560) LOG(INFO) Alphabet size=77\n","trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999551\n","trainer_interface.cc(592) LOG(INFO) Done! preprocessed 2126996 sentences.\n","unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n","unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=79272151\n","unigram_model_trainer.cc(312) LOG(INFO) Initialized 914179 seed sentencepieces\n","trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 2126996\n","trainer_interface.cc(609) LOG(INFO) Done! 855545\n","unigram_model_trainer.cc(602) LOG(INFO) Using 855545 sentences for EM training\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=348261 obj=11.8363 num_tokens=1880403 num_tokens/piece=5.39941\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=305492 obj=9.3713 num_tokens=1890818 num_tokens/piece=6.18942\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=229106 obj=9.34207 num_tokens=1966137 num_tokens/piece=8.58178\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=228978 obj=9.33396 num_tokens=1967928 num_tokens/piece=8.5944\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=171730 obj=9.37234 num_tokens=2068211 num_tokens/piece=12.0434\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=171727 obj=9.3644 num_tokens=2068822 num_tokens/piece=12.0472\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=128795 obj=9.41626 num_tokens=2176707 num_tokens/piece=16.9006\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=128795 obj=9.40609 num_tokens=2176599 num_tokens/piece=16.8997\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=96596 obj=9.47545 num_tokens=2289036 num_tokens/piece=23.697\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=96596 obj=9.46295 num_tokens=2288968 num_tokens/piece=23.6963\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=72447 obj=9.55314 num_tokens=2403420 num_tokens/piece=33.1749\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=72447 obj=9.53769 num_tokens=2403318 num_tokens/piece=33.1735\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=54335 obj=9.64723 num_tokens=2521527 num_tokens/piece=46.407\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=54335 obj=9.6278 num_tokens=2521141 num_tokens/piece=46.3999\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=40751 obj=9.75834 num_tokens=2641139 num_tokens/piece=64.8116\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=40751 obj=9.73434 num_tokens=2640944 num_tokens/piece=64.8069\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=30563 obj=9.89102 num_tokens=2765326 num_tokens/piece=90.4795\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=30563 obj=9.86158 num_tokens=2764870 num_tokens/piece=90.4646\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=22922 obj=10.0521 num_tokens=2895884 num_tokens/piece=126.336\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=22922 obj=10.0162 num_tokens=2895782 num_tokens/piece=126.332\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=17191 obj=10.2416 num_tokens=3036751 num_tokens/piece=176.648\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=17191 obj=10.1976 num_tokens=3037380 num_tokens/piece=176.684\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12893 obj=10.4595 num_tokens=3184882 num_tokens/piece=247.024\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12893 obj=10.4068 num_tokens=3185358 num_tokens/piece=247.061\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9669 obj=10.7118 num_tokens=3339442 num_tokens/piece=345.376\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9669 obj=10.6493 num_tokens=3339943 num_tokens/piece=345.428\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8800 obj=10.7515 num_tokens=3392709 num_tokens/piece=385.535\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8800 obj=10.7305 num_tokens=3393138 num_tokens/piece=385.584\n","trainer_interface.cc(687) LOG(INFO) Saving model: model/en_model.model\n","trainer_interface.cc(699) LOG(INFO) Saving vocabs: model/en_model.vocab\n"]}],"source":["train_tokenizer(\n","    text_path = en_data_path,\n","    model_prefix = \"model/en_model\"\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:40:32.495043Z","iopub.status.busy":"2024-03-09T14:40:32.494635Z","iopub.status.idle":"2024-03-09T14:40:32.551521Z","shell.execute_reply":"2024-03-09T14:40:32.550414Z","shell.execute_reply.started":"2024-03-09T14:40:32.495008Z"},"trusted":true},"outputs":[],"source":["bn_tokenizer = spm.SentencePieceProcessor(model_file='/kaggle/working/model/bn_model.model')\n","en_tokenizer = spm.SentencePieceProcessor(model_file='/kaggle/working/model/en_model.model')"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:42:26.322012Z","iopub.status.busy":"2024-03-09T14:42:26.321152Z","iopub.status.idle":"2024-03-09T14:42:26.326306Z","shell.execute_reply":"2024-03-09T14:42:26.325228Z","shell.execute_reply.started":"2024-03-09T14:42:26.321978Z"},"trusted":true},"outputs":[],"source":["bn_tokenizer.unk_id=999\n","en_tokenizer.unk_id=999"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:42:29.072278Z","iopub.status.busy":"2024-03-09T14:42:29.071536Z","iopub.status.idle":"2024-03-09T14:42:29.078812Z","shell.execute_reply":"2024-03-09T14:42:29.077845Z","shell.execute_reply.started":"2024-03-09T14:42:29.072246Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[50, 15, 12, 6870, 2266]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["en_tokenizer.encode(\"this is a translator code\")"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:42:33.156231Z","iopub.status.busy":"2024-03-09T14:42:33.155073Z","iopub.status.idle":"2024-03-09T14:42:33.162872Z","shell.execute_reply":"2024-03-09T14:42:33.161857Z","shell.execute_reply.started":"2024-03-09T14:42:33.156186Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[129, 39, 1222, 29, 4]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["bn_tokenizer.encode(\"এটি একটি অনুবাদক।\")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:42:38.050549Z","iopub.status.busy":"2024-03-09T14:42:38.050152Z","iopub.status.idle":"2024-03-09T14:42:38.056291Z","shell.execute_reply":"2024-03-09T14:42:38.055195Z","shell.execute_reply.started":"2024-03-09T14:42:38.050515Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['▁এটি', '▁একটি', '▁অনুবাদ', 'ক', '।']\n","[129, 39, 1222, 29, 4]\n"]}],"source":["print(bn_tokenizer.encode_as_pieces('এটি একটি অনুবাদক।'))\n","print(bn_tokenizer.encode_as_ids('এটি একটি অনুবাদক।'))"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:47:32.126434Z","iopub.status.busy":"2024-03-09T14:47:32.125706Z","iopub.status.idle":"2024-03-09T14:47:32.133224Z","shell.execute_reply":"2024-03-09T14:47:32.131975Z","shell.execute_reply.started":"2024-03-09T14:47:32.126393Z"},"trusted":true},"outputs":[],"source":["from torchtext.vocab import vocab\n","def build_vocab(sentences, tokenizer):\n","    counter = Counter()\n","    for sentence in sentences:\n","        if isinstance(sentence, list):\n","            sentence = sentence[0]\n","        counter.update(tokenizer.encode(sentence, out_type=str))\n","    return vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'], special_first=True)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T13:57:14.373294Z","iopub.status.busy":"2024-03-09T13:57:14.372995Z","iopub.status.idle":"2024-03-09T13:57:14.383829Z","shell.execute_reply":"2024-03-09T13:57:14.382950Z","shell.execute_reply.started":"2024-03-09T13:57:14.373262Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'0.16.2'"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["torchtext.__version__"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:47:35.076208Z","iopub.status.busy":"2024-03-09T14:47:35.075335Z","iopub.status.idle":"2024-03-09T14:50:12.329567Z","shell.execute_reply":"2024-03-09T14:50:12.328446Z","shell.execute_reply.started":"2024-03-09T14:47:35.076170Z"},"trusted":true},"outputs":[],"source":["bn_vocab = build_vocab(trainbn, bn_tokenizer)\n","bn_vocab.set_default_index(999)\n","en_vocab = build_vocab(trainen, en_tokenizer)\n","en_vocab.set_default_index(999)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T16:04:07.308457Z","iopub.status.busy":"2024-03-09T16:04:07.308029Z","iopub.status.idle":"2024-03-09T16:04:07.451692Z","shell.execute_reply":"2024-03-09T16:04:07.450713Z","shell.execute_reply.started":"2024-03-09T16:04:07.308427Z"},"trusted":true},"outputs":[],"source":["import pickle\n","# open a file, where you want to store the data\n","file = open('/kaggle/working/model/bn_vocab.pkl', 'wb')\n","# dump information to that file\n","pickle.dump(bn_vocab, file)\n","file.close()\n","file = open('/kaggle/working/model/en_vocab.pkl', 'wb')\n","pickle.dump(en_vocab, file)\n","file.close()"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:50:26.775988Z","iopub.status.busy":"2024-03-09T14:50:26.775569Z","iopub.status.idle":"2024-03-09T14:57:34.195586Z","shell.execute_reply":"2024-03-09T14:57:34.194541Z","shell.execute_reply.started":"2024-03-09T14:50:26.775956Z"},"trusted":true},"outputs":[],"source":["def data_process(bn, en):\n","    data = []\n","    for (raw_bn, raw_en) in zip(bn, en):\n","        bn_tensor_ = torch.tensor([bn_vocab[token] for token in bn_tokenizer.encode(raw_bn, out_type=str)],dtype=torch.long)\n","        en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer.encode(raw_en, out_type=str)],dtype=torch.long)\n","        data.append((bn_tensor_, en_tensor_))\n","    return data\n","train_data = data_process(trainbn, trainen)\n","val_data = data_process(val_bn, val_en)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T15:34:56.200840Z","iopub.status.busy":"2024-03-09T15:34:56.200051Z","iopub.status.idle":"2024-03-09T15:40:31.360205Z","shell.execute_reply":"2024-03-09T15:40:31.359069Z","shell.execute_reply.started":"2024-03-09T15:34:56.200803Z"},"trusted":true},"outputs":[],"source":["torch.save(train_data, '/kaggle/working/model/train_data.pth')\n","torch.save(val_data, '/kaggle/working/model/val_data.pth')"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:59:51.645629Z","iopub.status.busy":"2024-03-09T14:59:51.644806Z","iopub.status.idle":"2024-03-09T14:59:51.655078Z","shell.execute_reply":"2024-03-09T14:59:51.654042Z","shell.execute_reply.started":"2024-03-09T14:59:51.645592Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 150\n","PAD_IDX = bn_vocab['<pad>']\n","BOS_IDX = bn_vocab['<bos>']\n","EOS_IDX = bn_vocab['<eos>']\n","\n","def generate_batch(data_batch):\n","    bn_batch, en_batch = [], []\n","    for (bn_item, en_item) in data_batch:\n","        bn_batch.append(torch.cat([torch.tensor([BOS_IDX]), bn_item, torch.tensor([EOS_IDX])], dim=0))\n","        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n","    bn_batch = pad_sequence(bn_batch, padding_value=PAD_IDX)\n","    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n","    return bn_batch, en_batch\n","\n","train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=True, collate_fn=generate_batch)\n","val_iter = DataLoader(val_data, batch_size=BATCH_SIZE,shuffle=True, collate_fn=generate_batch)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T14:59:54.734940Z","iopub.status.busy":"2024-03-09T14:59:54.734025Z","iopub.status.idle":"2024-03-09T14:59:54.748219Z","shell.execute_reply":"2024-03-09T14:59:54.747151Z","shell.execute_reply.started":"2024-03-09T14:59:54.734904Z"},"trusted":true},"outputs":[],"source":["from torch.nn import (TransformerEncoder, TransformerDecoder,\n","                      TransformerEncoderLayer, TransformerDecoderLayer)\n","\n","\n","class BanglaTransformer(nn.Module):\n","    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n","                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n","                 dim_feedforward:int = 512, dropout:float = 0.1):\n","        super(BanglaTransformer, self).__init__()\n","        encoder_layer = TransformerEncoderLayer(\n","            d_model=emb_size, \n","            nhead=NHEAD,\n","            dim_feedforward=dim_feedforward\n","            )\n","        self.transformer_encoder = TransformerEncoder(\n","            encoder_layer, \n","            num_layers=num_encoder_layers\n","            )\n","        decoder_layer = TransformerDecoderLayer(\n","            d_model=emb_size, \n","            nhead=NHEAD,\n","            dim_feedforward=dim_feedforward\n","            )\n","        self.transformer_decoder = TransformerDecoder(\n","            decoder_layer, \n","            num_layers=num_decoder_layers\n","            )\n","\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n","\n","    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n","                tgt_mask: Tensor, src_padding_mask: Tensor,\n","                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n","        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n","                                        tgt_padding_mask, memory_key_padding_mask)\n","        return self.generator(outs)\n","\n","    def encode(self, src: Tensor, src_mask: Tensor):\n","        return self.transformer_encoder(self.positional_encoding(\n","                            self.src_tok_emb(src)), src_mask)\n","\n","    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n","        return self.transformer_decoder(self.positional_encoding(\n","                          self.tgt_tok_emb(tgt)), memory,\n","                          tgt_mask)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T15:00:01.062506Z","iopub.status.busy":"2024-03-09T15:00:01.061551Z","iopub.status.idle":"2024-03-09T15:00:01.073049Z","shell.execute_reply":"2024-03-09T15:00:01.072032Z","shell.execute_reply.started":"2024-03-09T15:00:01.062472Z"},"trusted":true},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        pos_embedding = torch.zeros((maxlen, emb_size))\n","        pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        pos_embedding = pos_embedding.unsqueeze(-2)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding', pos_embedding)\n","\n","    def forward(self, token_embedding: Tensor):\n","        return self.dropout(token_embedding +\n","                            self.pos_embedding[:token_embedding.size(0),:])\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T15:00:05.108181Z","iopub.status.busy":"2024-03-09T15:00:05.107810Z","iopub.status.idle":"2024-03-09T15:00:05.116783Z","shell.execute_reply":"2024-03-09T15:00:05.115632Z","shell.execute_reply.started":"2024-03-09T15:00:05.108156Z"},"trusted":true},"outputs":[],"source":["def generate_square_subsequent_mask(sz):\n","    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[0]\n","    tgt_seq_len = tgt.shape[0]\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n","\n","    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n","    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T15:00:08.550720Z","iopub.status.busy":"2024-03-09T15:00:08.550305Z","iopub.status.idle":"2024-03-09T15:00:11.661555Z","shell.execute_reply":"2024-03-09T15:00:11.660448Z","shell.execute_reply.started":"2024-03-09T15:00:08.550665Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]}],"source":["from tqdm import tqdm\n","SRC_VOCAB_SIZE = len(bn_vocab)\n","TGT_VOCAB_SIZE = len(en_vocab)\n","EMB_SIZE = 512\n","NHEAD = 8\n","FFN_HID_DIM = 512\n","BATCH_SIZE = 150\n","NUM_ENCODER_LAYERS = 6\n","NUM_DECODER_LAYERS = 6\n","NUM_EPOCHS = 2\n","\n","\n","transformer = BanglaTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n","                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n","                                 FFN_HID_DIM)\n","\n","for p in transformer.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","transformer = transformer.to(device)\n","\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","\n","optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n","\n","def train_epoch(model, train_iter, optimizer):\n","    model.train()\n","    losses = 0\n","    for idx, (src, tgt) in enumerate(train_iter):\n","#         print(\"training iter : \", idx)\n","#     for idx in tqdm(range(len(train_iter))):\n","#         src, tgt = train_iter[idx]\n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","\n","        tgt_input = tgt[:-1, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,\n","                                src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        optimizer.zero_grad()\n","\n","        tgt_out = tgt[1:,:]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        losses += loss.item()\n","    return losses / len(train_iter)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T15:00:22.534444Z","iopub.status.busy":"2024-03-09T15:00:22.533880Z","iopub.status.idle":"2024-03-09T15:00:22.542658Z","shell.execute_reply":"2024-03-09T15:00:22.541343Z","shell.execute_reply.started":"2024-03-09T15:00:22.534412Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, val_iter):\n","    model.eval()\n","    losses = 0\n","    for idx, (src, tgt) in (enumerate(val_iter)):\n","#         print(idx)\n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","\n","        tgt_input = tgt[:-1, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,\n","                                  src_padding_mask, tgt_padding_mask, src_padding_mask)\n","        tgt_out = tgt[1:,:]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        losses += loss.item()\n","    return losses / len(val_iter)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T15:00:29.580529Z","iopub.status.busy":"2024-03-09T15:00:29.580144Z","iopub.status.idle":"2024-03-09T15:00:33.166308Z","shell.execute_reply":"2024-03-09T15:00:33.164465Z","shell.execute_reply.started":"2024-03-09T15:00:29.580498Z"},"trusted":true},"outputs":[],"source":["for epoch in range(1, NUM_EPOCHS+1):\n","    start_time = time.time()\n","    train_loss = train_epoch(transformer, train_iter, optimizer)\n","#     if epoch % 5 == 0:\n","    val_loss = evaluate(transformer, val_iter)\n","    end_time = time.time()\n","    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, val loss : {val_loss:.3f} \"\n","          f\"Epoch time = {(end_time - start_time):.3f}s\"))\n","\n","        \n","    # save model + checkpoint to resume training later\n","    if (epoch%50==0):\n","        torch.save({\n","          'epoch': epoch,\n","          'model_state_dict': transformer.state_dict(),\n","          'optimizer_state_dict': optimizer.state_dict(),\n","          'loss': train_loss,\n","          }, 'model/model_checkpoint.tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-09T14:04:18.897394Z","iopub.status.idle":"2024-03-09T14:04:18.897695Z","shell.execute_reply":"2024-03-09T14:04:18.897558Z","shell.execute_reply.started":"2024-03-09T14:04:18.897545Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-09T14:04:18.898964Z","iopub.status.idle":"2024-03-09T14:04:18.899298Z","shell.execute_reply":"2024-03-09T14:04:18.899133Z","shell.execute_reply.started":"2024-03-09T14:04:18.899120Z"},"trusted":true},"outputs":[],"source":["def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    src = src.to(device)\n","    src_mask = src_mask.to(device)\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n","    for i in range(max_len-1):\n","        memory = memory.to(device)\n","        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                                    .type(torch.bool)).to(device)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim = 1)\n","        next_word = next_word.item()\n","        ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","def translate(model, src, src_vocab, tgt_vocab, src_tokenizer):\n","    model.eval()\n","    tokens = [BOS_IDX] + [src_vocab.get_stoi()[tok] for tok in src_tokenizer.encode(src, out_type=str)]+ [EOS_IDX]\n","    num_tokens = len(tokens)\n","    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n","    p_text = \" \".join([tgt_vocab.get_itos()[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n","    pts = \" \".join(list(map(lambda x : x , p_text.replace(\" \", \"\").split(\"▁\"))))\n","    return pts.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-09T14:04:18.900104Z","iopub.status.idle":"2024-03-09T14:04:18.900443Z","shell.execute_reply":"2024-03-09T14:04:18.900297Z","shell.execute_reply.started":"2024-03-09T14:04:18.900283Z"},"trusted":true},"outputs":[],"source":["text = \"আবার সবাইকে যার যার ইচ্ছামতো চলতে দিলে সমতা রক্ষা করা অসম্ভব হয়ে যায়।\"\n","pre = translate(transformer, text, bn_vocab, en_vocab, bn_tokenizer)\n","print(f\"input : {text}\")\n","print(f\"prediction: {pre}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-09T14:04:18.903204Z","iopub.status.idle":"2024-03-09T14:04:18.903506Z","shell.execute_reply":"2024-03-09T14:04:18.903367Z","shell.execute_reply.started":"2024-03-09T14:04:18.903354Z"},"trusted":true},"outputs":[],"source":["# save model + checkpoint to resume training later\n","torch.save({\n","  'epoch': \"Final\",\n","  'model_state_dict': transformer.state_dict(),\n","  'optimizer_state_dict': optimizer.state_dict(),\n","  'loss': train_loss,\n","  }, '/kaggle/working/model/model_checkpoint.pt')"]},{"cell_type":"markdown","metadata":{},"source":["**INFERENCE**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-09T14:04:18.904756Z","iopub.status.idle":"2024-03-09T14:04:18.905085Z","shell.execute_reply":"2024-03-09T14:04:18.904930Z","shell.execute_reply.started":"2024-03-09T14:04:18.904917Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-09T14:04:18.911745Z","iopub.status.idle":"2024-03-09T14:04:18.912050Z","shell.execute_reply":"2024-03-09T14:04:18.911911Z","shell.execute_reply.started":"2024-03-09T14:04:18.911898Z"},"trusted":true},"outputs":[],"source":["PATH = \"/kaggle/working/model/model_checkpoint.pt\"\n","\n","model = BanglaTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n","                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n","                                 FFN_HID_DIM)\n","model.to(device)\n","checkpoint = torch.load(PATH)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","epoch = checkpoint['epoch']\n","loss = checkpoint['loss']\n","\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-09T14:04:18.914110Z","iopub.status.idle":"2024-03-09T14:04:18.914484Z","shell.execute_reply":"2024-03-09T14:04:18.914328Z","shell.execute_reply.started":"2024-03-09T14:04:18.914296Z"},"trusted":true},"outputs":[],"source":["def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    src = src.to(device)\n","    src_mask = src_mask.to(device)\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n","    for i in range(max_len-1):\n","        memory = memory.to(device)\n","        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                                    .type(torch.bool)).to(device)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim = 1)\n","        next_word = next_word.item()\n","        ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","def translate(model, src, src_vocab, tgt_vocab, src_tokenizer):\n","#     model.eval()\n","    tokens = [BOS_IDX] + [src_vocab.get_stoi()[tok] for tok in src_tokenizer.encode(src, out_type=str)]+ [EOS_IDX]\n","    num_tokens = len(tokens)\n","    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n","    p_text = \" \".join([tgt_vocab.get_itos()[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n","    pts = \" \".join(list(map(lambda x : x , p_text.replace(\" \", \"\").split(\"▁\"))))\n","    return pts.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-09T14:04:18.915529Z","iopub.status.idle":"2024-03-09T14:04:18.915966Z","shell.execute_reply":"2024-03-09T14:04:18.915762Z","shell.execute_reply.started":"2024-03-09T14:04:18.915744Z"},"trusted":true},"outputs":[],"source":["for bn,en in zip(bdata[-10:], edata[-10:]):\n","    #text = \"আমি আবার বিয়ে করেছি।\"\n","    pre = translate(model, bn, bn_vocab, en_vocab, bn_tokenizer)\n","    print(f\"input : {bn}\")\n","    print(f\"Ground Truth : {en}\")\n","    print(f\"prediction: {pre}\")\n","    print(\"================================\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4566793,"sourceId":7799666,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
